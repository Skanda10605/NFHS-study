{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24cd32a-0fb3-465a-aecb-8a08434fa7ed",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4164ebcf-043e-4ac5-aa89-54b352a55b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5972 columns found\n",
      "['caseid', 'v000', 'v001', 'v002', 'v003', 'v004', 'v005', 'v006', 'v007', 'v008', 'v008a', 'v009', 'v010', 'v011', 'v012', 'v013', 'v014', 'v015', 'v016', 'v017', 'v018', 'v019', 'v019a', 'v020', 'v021']\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "_, meta = pyreadstat.read_dta(\"IAIR7EFL.DTA\", metadataonly=True)\n",
    "print(len(meta.column_names), \"columns found\")\n",
    "print(meta.column_names[:25])  #just 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d46d8a-1165-47c5-af0c-391f255cb007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged as implausible BMI: 904 rows\n",
      "count    699362.000000\n",
      "mean         22.284112\n",
      "std           4.308438\n",
      "min          12.000000\n",
      "25%          19.290000\n",
      "50%          21.680000\n",
      "75%          24.510000\n",
      "max          59.990000\n",
      "Name: bmi, dtype: float64\n",
      "Missing BMI before → after: 23849 → 24753 of 724115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file ( will upload in git ) \n",
    "df = pd.read_parquet(\"nfhs5_ir_thin.parquet\")\n",
    "\n",
    "\n",
    "n_total = len(df)\n",
    "missing_before = df[\"bmi\"].isna().sum()\n",
    "\n",
    "# Mark impossible BMI values as missing\n",
    "bad = (df[\"bmi\"] <= 10) | (df[\"bmi\"] >= 60)\n",
    "df.loc[bad, \"bmi\"] = pd.NA\n",
    "\n",
    "print(\"Flagged as implausible BMI:\", bad.sum(), \"rows\")\n",
    "\n",
    "# Save\n",
    "df.to_parquet(\"nfhs5_ir_thin_clean.parquet\", index=False)\n",
    "\n",
    "print(df[\"bmi\"].describe())\n",
    "print(\"Missing BMI before → after:\", missing_before, \"→\", df[\"bmi\"].isna().sum(), \"of\", n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62eaeb2b-dc69-48da-a0e6-78833b1a5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter cwd: C:\\Users\\Lion\\NFHS\\2019-2021\\Individual Recode-IAIR7EDT\n",
      "File exists at path? -> True\n",
      "Size (MB): 2062.0\n",
      "Columns found: 530\n"
     ]
    }
   ],
   "source": [
    "import os, pyreadstat\n",
    "\n",
    "\n",
    "path = r\"D:\\NFHS\\DataBase-Files\\2019-2021\\Household Member Recode-IAPR7EDT\\IAPR7EFL.DTA\"\n",
    "\n",
    "print(\"Jupyter cwd:\", os.getcwd())\n",
    "print(\"File exists at path? ->\", os.path.exists(path))\n",
    "\n",
    "if os.path.exists(path):\n",
    "    print(\"Size (MB):\", round(os.path.getsize(path)/1e6, 1))\n",
    "    _, meta_pr = pyreadstat.read_dta(path, metadataonly=True)\n",
    "    print(\"Columns found:\", len(meta_pr.column_names))\n",
    "else:\n",
    "    print(\"Path is wrong for this notebook. Paste the exact full path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1989487-0cd5-45dc-b649-1b90bd5e6e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== JOIN + DESIGN ===\n",
      "         hvidx | line number\n",
      "         hv001 | cluster number\n",
      "         hv002 | household number\n",
      "         hv005 | household sample weight (6 decimals)\n",
      "         hv021 | primary sampling unit\n",
      "         hv022 | sample strata for sampling errors\n",
      "         hv023 | stratification used in sample design\n",
      "         hv028 | household weight for male subsample (6 decimals)\n",
      "         hv035 | number of eligible children for height and weight\n",
      "      shweight | household weight (6 decimals) (state level)\n",
      "     shmweight | household weight - male subsample (6 decimals) (state level)\n",
      "         hv120 | children eligibility for height/weight and hemoglobin\n",
      "           ha2 | woman's weight in kilograms (1 decimal)\n",
      "          ha11 | weight/height standard deviation (dhs)\n",
      "          ha12 | weight/height percent ref. median (dhs)\n",
      "         ha12a | weight/height percent ref. median (fog)\n",
      "         ha12b | weight/height percent ref. median (who)\n",
      "          ha13 | result of measurement - height/weight\n",
      "          ha69 | na - hiv weight (6 decimals)\n",
      "           hc2 | child's weight in kilograms (1 decimal)\n",
      "           hc7 | weight/age percentile\n",
      "           hc8 | weight/age standard deviation\n",
      "           hc9 | weight/age percent of ref. median\n",
      "          hc10 | weight/height percentile\n",
      "          hc11 | weight/height standard deviation\n",
      "          hc12 | weight/height percent of ref. median\n",
      "          hc13 | result of measurement - height/weight\n",
      "          hc71 | weight/age standard deviation (new who)\n",
      "          hc72 | weight/height standard deviation (new who)\n",
      "          hc2a | child's weight in kilograms (1 decimal) - first measurement\n",
      "\n",
      "=== HEMOGLOBIN ===\n",
      "         hv042 | household selected for hemoglobin\n",
      "         hv120 | children eligibility for height/weight and hemoglobin\n",
      "        shb14a | 30 minutes prior to bp measure: eaten\n",
      "        shb14b | 30 minutes prior to bp measure: had coffee, tea\n",
      "        shb14c | 30 minutes prior to bp measure: smoked any tobacco product\n",
      "        shb14d | 30 minutes prior to bp measure: use any other type of tobacco\n",
      "         shb15 | arm circumference\n",
      "         shb16 | blood pressure monitor cuff size\n",
      "         shb17 | time of first bp reading: (hhmm - 24 hour clock)\n",
      "        shb18s | first systolic reading\n",
      "        shb18d | first diastolic reading\n",
      "         shb19 | blood pressure ever been checked previously\n",
      "         shb20 | told had high bp on two or more occasions by doctor or other health professional\n",
      "         shb21 | currently taking a prescribed medicine to lower bp\n",
      "         shb24 | time of second bp reading: (hhmm - 24 hour clock)\n",
      "        shb25s | second systolic reading\n",
      "        shb25d | second diastolic reading\n",
      "         shb28 | time of third bp reading: (hhmm - 24 hour clock)\n",
      "        shb29s | third systolic reading\n",
      "        shb29d | third diastolic reading\n",
      "         shb53 | time since last ate\n",
      "         shb54 | time since last drank, something other than plain water\n",
      "         shb55 | blood glucose ever been checked\n",
      "         shb56 | told high blood glucose on two or more occations by doctor or other health profe\n",
      "         shb57 | currently taking a prescribed medicine to lower blood glucose\n",
      "         shb73 | time of blood glucose reading: (hhmm - 24 hour clock)\n",
      "         shb74 | glucose level\n",
      "         shb79 | ever undergone a screening test for cervical cancer\n",
      "         shb80 | ever undergone a breast examination for breast cancer\n",
      "         shb81 | ever undergone an oral cavity examination for oral cancer\n",
      "\n",
      "=== GLUCOSE ===\n",
      "         shb55 | blood glucose ever been checked\n",
      "         shb56 | told high blood glucose on two or more occations by doctor or other health profe\n",
      "         shb57 | currently taking a prescribed medicine to lower blood glucose\n",
      "         shb73 | time of blood glucose reading: (hhmm - 24 hour clock)\n",
      "         shb74 | glucose level\n",
      "        shb20c | read consent statement - blood glucose\n",
      "\n",
      "=== WAIST ===\n",
      "         shb15 | arm circumference\n",
      "         sh305 | waist curcumference\n",
      "\n",
      "=== BP SYSTOLIC ===\n",
      "         shb16 | blood pressure monitor cuff size\n",
      "        shb18s | first systolic reading\n",
      "         shb19 | blood pressure ever been checked previously\n",
      "        shb25s | second systolic reading\n",
      "        shb29s | third systolic reading\n",
      "        shb10c | read consent statement - blood pressure\n",
      "         shb23 | consent given for second blood pressure reading\n",
      "         shb27 | consent given for third blood pressure reading\n",
      "\n",
      "=== BP DIASTOLIC ===\n",
      "         shb16 | blood pressure monitor cuff size\n",
      "        shb18d | first diastolic reading\n",
      "         shb19 | blood pressure ever been checked previously\n",
      "        shb25d | second diastolic reading\n",
      "        shb29d | third diastolic reading\n",
      "        shb10c | read consent statement - blood pressure\n",
      "         shb23 | consent given for second blood pressure reading\n",
      "         shb27 | consent given for third blood pressure reading\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "\n",
    "path = r\"D:\\NFHS\\DataBase-Files\\2019-2021\\Household Member Recode-IAPR7EDT\\IAPR7EFL.DTA\"\n",
    "\n",
    "\n",
    "_, meta_pr = pyreadstat.read_dta(path, metadataonly=True)\n",
    "names  = meta_pr.column_names\n",
    "labels = meta_pr.column_labels  \n",
    "\n",
    "def search(keys, limit=30):\n",
    "    keys = [k.lower() for k in keys]\n",
    "    out = []\n",
    "    for n, lab in zip(names, labels):\n",
    "        text = (f\"{n} || {lab}\").lower()\n",
    "        if any(k in text for k in keys):\n",
    "            out.append((n, lab))\n",
    "            if len(out) >= limit:\n",
    "                break\n",
    "    return out\n",
    "\n",
    "groups = {\n",
    "    \"JOIN + DESIGN\": [\"hv001\",\"hv002\",\"hvidx\",\"hv005\",\"weight\",\"hv021\",\"hv022\",\"hv023\",\"psu\",\"strata\"],\n",
    "    \"HEMOGLOBIN\":    [\"hemoglobin\",\"haemoglobin\",\"hb\",\"anemia\"],\n",
    "    \"GLUCOSE\":       [\"glucose\",\"blood sugar\",\"random\",\"rpg\"],\n",
    "    \"WAIST\":         [\"waist\",\"abdominal\",\"circumference\"],\n",
    "    \"BP SYSTOLIC\":   [\"systolic\",\"sbp\",\"blood pressure\"],\n",
    "    \"BP DIASTOLIC\":  [\"diastolic\",\"dbp\",\"blood pressure\"],\n",
    "}\n",
    "\n",
    "for title, keys in groups.items():\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for n, lab in search(keys):\n",
    "        print(f\"{n:>14} | {lab}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a327f63-4554-4386-baa7-b789f714a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CANDIDATES FOR HEMOGLOBIN ===\n",
      "       hv042 | household selected for hemoglobin\n",
      "      hv253a | na - dwelling sprayed by: government worker/program\n",
      "       sh72e | health insurance or scheme: community health insurance programme\n",
      "       hv120 | children eligibility for height/weight and hemoglobin\n",
      "         ha2 | woman's weight in kilograms (1 decimal)\n",
      "        ha52 | read consent statement - hemoglobin\n",
      "        ha53 | hemoglobin level (g/dl - 1 decimal)\n",
      "        ha55 | result of measurement - hemoglobin\n",
      "        ha56 | hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)\n",
      "        ha57 | anemia level\n",
      "        ha58 | na - agrees to referral - anemia\n",
      "         hc2 | child's weight in kilograms (1 decimal)\n",
      "        hc52 | read consent statement - hemoglobin\n",
      "        hc53 | hemoglobin level (g/dl - 1 decimal)\n",
      "        hc55 | result of measurement - hemoglobin\n",
      "        hc56 | hemoglobin level adjusted for altitude (g/dl - 1 decimal)\n",
      "        hc57 | anemia level\n",
      "        hc58 | na - agrees to referral - anemia\n",
      "        hc2a | child's weight in kilograms (1 decimal) - first measurement\n",
      "        hc2b | na - child's weight in kilograms (1 decimal) - re-measurement\n",
      "         hb2 | man's weight in kilograms (1 decimal)\n",
      "        hb52 | read consent statement - hemoglobin\n",
      "        hb53 | hemoglobin level (g/dl - 1 decimal)\n",
      "        hb55 | result of measurement - hemoglobin\n",
      "        hb56 | hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)\n",
      "        hb57 | anemia level\n",
      "        hb58 | na - agrees to referral - anemia\n"
     ]
    }
   ],
   "source": [
    "import re, pyreadstat\n",
    "\n",
    "path = r\"D:\\NFHS\\DataBase-Files\\2019-2021\\Household Member Recode-IAPR7EDT\\IAPR7EFL.DTA\"\n",
    "\n",
    "_, meta_pr = pyreadstat.read_dta(path, metadataonly=True)\n",
    "names  = meta_pr.column_names\n",
    "labels = meta_pr.column_labels\n",
    "\n",
    "def grep(patterns, limit=50):\n",
    "    out = []\n",
    "    for n, lab in zip(names, labels):\n",
    "        text = f\"{n} || {lab}\"\n",
    "        low  = text.lower()\n",
    "        if any(re.search(p, low) for p in patterns):\n",
    "            out.append((n, lab))\n",
    "            if len(out) >= limit:\n",
    "                break\n",
    "    return out\n",
    "\n",
    "patterns = [\n",
    "    r\"hemoglobin\", r\"haemoglobin\", r\"\\bhb\\b\", r\"\\bhgb\\b\",\n",
    "    r\"anemi\", r\"g/dl\", r\"gram\", r\"blood haem?oglobin\"\n",
    "]\n",
    "\n",
    "hits = grep(patterns, limit=100)\n",
    "print(\"=== CANDIDATES FOR HEMOGLOBIN ===\")\n",
    "for n, lab in hits:\n",
    "    print(f\"{n:>12} | {lab}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e664cde-ae20-41ff-9a71-3772fada5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pr_df: (2843917, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "if os.path.exists(\"nfhs5_pr_thin.parquet\"):\n",
    "    pr_df = pd.read_parquet(\"nfhs5_pr_thin.parquet\")\n",
    "    print(\"Loaded pr_df:\", pr_df.shape)\n",
    "else:\n",
    "    print(\"nfhs5_pr_thin.parquet not found — you can rebuild it if needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb1b28d-e394-4b74-b64f-778dd59f47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved nfhs5_pr_thin.parquet\n",
      "Shape: (2843917, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pr_df[\"ha57\"] = pd.to_numeric(pr_df.get(\"ha57\"), errors=\"coerce\").astype(\"Int16\")\n",
    "\n",
    "\n",
    "pr_df.to_parquet(\"nfhs5_pr_thin.parquet\", index=False)\n",
    "print(\"Saved nfhs5_pr_thin.parquet\")\n",
    "print(\"Shape:\", pr_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e9c1d2-b431-4315-85b5-c76def4e6fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (724115, 37)\n",
      "\n",
      "Non-missing counts (biomarkers):\n",
      "ha56      724115\n",
      "sh305     707438\n",
      "ha53      702539\n",
      "shb74     702492\n",
      "shb18s    699184\n",
      "shb18d    698971\n",
      "ha57      690153\n",
      "shb25s    677866\n",
      "shb25d    677820\n",
      "shb29s    651850\n",
      "shb29d    651810\n",
      "dtype: int64\n",
      "\n",
      "Saved nfhs5_women_biomarkers.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ir = pd.read_parquet(\"nfhs5_ir_thin_clean.parquet\")\n",
    "pr = pd.read_parquet(\"nfhs5_pr_thin.parquet\")\n",
    "\n",
    "\n",
    "for c in [\"v001\",\"v002\",\"v003\"]:\n",
    "    ir[c] = pd.to_numeric(ir[c], errors=\"coerce\").astype(\"Int32\")\n",
    "for c in [\"hv001\",\"hv002\",\"hvidx\"]:\n",
    "    pr[c] = pd.to_numeric(pr[c], errors=\"coerce\").astype(\"Int32\")\n",
    "\n",
    "\n",
    "m = ir.merge(\n",
    "    pr,\n",
    "    left_on=[\"v001\",\"v002\",\"v003\"],\n",
    "    right_on=[\"hv001\",\"hv002\",\"hvidx\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"  \n",
    ")\n",
    "\n",
    "s\n",
    "biom_cols = [\"shb18s\",\"shb25s\",\"shb29s\",\"shb18d\",\"shb25d\",\"shb29d\",\"shb74\",\"sh305\",\"ha53\",\"ha56\",\"ha57\"]\n",
    "coverage = m[biom_cols].notna().sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Merged shape:\", m.shape)\n",
    "print(\"\\nNon-missing counts (biomarkers):\")\n",
    "print(coverage)\n",
    "\n",
    "\n",
    "m.to_parquet(\"nfhs5_women_biomarkers.parquet\", index=False)\n",
    "print(\"\\nSaved nfhs5_women_biomarkers.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f61403-a8fc-4d87-9b39-5c54667e0a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP clean non-missing: 698727\n",
      "DBP clean non-missing: 698564\n",
      "Saved with clean BP → nfhs5_women_biomarkers.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "\n",
    "# average of 2nd & 3rd readings (uses the one that exists if the other is NaN)\n",
    "sbp23 = m[[\"shb25s\",\"shb29s\"]].mean(axis=1, skipna=True)\n",
    "dbp23 = m[[\"shb25d\",\"shb29d\"]].mean(axis=1, skipna=True)\n",
    "\n",
    "# if both are NaN, fall back to 1st reading\n",
    "m[\"sbp_clean\"] = sbp23.where(~sbp23.isna(), m[\"shb18s\"])\n",
    "m[\"dbp_clean\"] = dbp23.where(~dbp23.isna(), m[\"shb18d\"])\n",
    "\n",
    "# mark implausible values as missing (conservative bounds)\n",
    "m.loc[~m[\"sbp_clean\"].between(70, 260), \"sbp_clean\"] = pd.NA\n",
    "m.loc[~m[\"dbp_clean\"].between(40, 150), \"dbp_clean\"] = pd.NA\n",
    "\n",
    "print(\"SBP clean non-missing:\", m[\"sbp_clean\"].notna().sum())\n",
    "print(\"DBP clean non-missing:\", m[\"dbp_clean\"].notna().sum())\n",
    "\n",
    "m.to_parquet(\"nfhs5_women_biomarkers.parquet\", index=False) \n",
    "print(\"Saved with clean BP → nfhs5_women_biomarkers.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb19e059-9dfe-4b15-98b9-e41a553a8bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hb non-missing: 52\n",
      "Waist non-missing: 697562\n",
      "Glucose non-missing: 690636\n",
      "Saved with clean Hb/Waist/Glucose → nfhs5_women_biomarkers.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "\n",
    "# Hemoglobin (prefer adjusted ha56 fallback ha53)\n",
    "m[\"hb_gdl\"] = m[\"ha56\"]\n",
    "m.loc[m[\"hb_gdl\"].isna(), \"hb_gdl\"] = m[\"ha53\"]\n",
    "# plausible range 5–20 g/dL\n",
    "m.loc[~m[\"hb_gdl\"].between(5, 20), \"hb_gdl\"] = pd.NA\n",
    "\n",
    "# Waist circumference (cm), plausible 40–150 cm\n",
    "m[\"waist_cm\"] = m[\"sh305\"]\n",
    "m.loc[~m[\"waist_cm\"].between(40, 150), \"waist_cm\"] = pd.NA\n",
    "\n",
    "# Random glucose (mg/dL), plausible 40–500 mg/dL\n",
    "m[\"glucose_mgdl\"] = m[\"shb74\"]\n",
    "m.loc[~m[\"glucose_mgdl\"].between(40, 500), \"glucose_mgdl\"] = pd.NA\n",
    "\n",
    "# Quick coverage after cleaning\n",
    "print(\"Hb non-missing:\", m[\"hb_gdl\"].notna().sum())\n",
    "print(\"Waist non-missing:\", m[\"waist_cm\"].notna().sum())\n",
    "print(\"Glucose non-missing:\", m[\"glucose_mgdl\"].notna().sum())\n",
    "\n",
    "# Save back\n",
    "m.to_parquet(\"nfhs5_women_biomarkers.parquet\", index=False)\n",
    "print(\"Saved with clean Hb/Waist/Glucose → nfhs5_women_biomarkers.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4aa5693-542b-413e-8832-22a4a390a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha56 describe (adjusted Hb):\n",
      "count    724115.000000\n",
      "mean        156.650629\n",
      "std         187.096541\n",
      "min          20.000000\n",
      "25%         107.000000\n",
      "50%         118.000000\n",
      "75%         128.000000\n",
      "max         997.000000\n",
      "Name: ha56, dtype: float64\n",
      "\n",
      "ha53 describe (raw Hb):\n",
      "count    702539.000000\n",
      "mean        131.367988\n",
      "std         116.805252\n",
      "min          20.000000\n",
      "25%         107.000000\n",
      "50%         117.000000\n",
      "75%         127.000000\n",
      "max         998.000000\n",
      "Name: ha53, dtype: float64\n",
      "\n",
      "Counts > 50  → ha56: 722,698 | ha53: 701,379\n",
      "\n",
      "Sample (first 10 non-missing rows):\n",
      "    ha56   ha53\n",
      "0  106.0  117.0\n",
      "1   82.0   93.0\n",
      "2   83.0   94.0\n",
      "3   72.0   83.0\n",
      "4   93.0  104.0\n",
      "5   62.0   73.0\n",
      "6   63.0   74.0\n",
      "7   76.0   87.0\n",
      "8   85.0   96.0\n",
      "9  134.0  145.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "\n",
    "print(\"ha56 describe (adjusted Hb):\")\n",
    "print(m[\"ha56\"].describe())\n",
    "\n",
    "print(\"\\nha53 describe (raw Hb):\")\n",
    "print(m[\"ha53\"].describe())\n",
    "\n",
    "\n",
    "gt50_56 = (m[\"ha56\"] > 50).sum()\n",
    "gt50_53 = (m[\"ha53\"] > 50).sum()\n",
    "print(f\"\\nCounts > 50  → ha56: {gt50_56:,} | ha53: {gt50_53:,}\")\n",
    "\n",
    "# few non-missing rows to see actual numbers\n",
    "print(\"\\nSample (first 10 non-missing rows):\")\n",
    "print(m.loc[m[\"ha56\"].notna() | m[\"ha53\"].notna(), [\"ha56\",\"ha53\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eabc6e1-3038-4a75-b7e6-8d46c3b0276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hb non-missing after scaling & cleaning: 688803\n",
      "Saved with corrected Hb → nfhs5_women_biomarkers.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "\n",
    "# Scale to g/dL: 118 -> 11.8\n",
    "hb56 = m[\"ha56\"] / 10.0\n",
    "hb53 = m[\"ha53\"] / 10.0\n",
    "\n",
    "# Prefer adjusted (ha56); fallback to raw (ha53)\n",
    "m[\"hb_gdl\"] = hb56.fillna(hb53)\n",
    "\n",
    "# Keep plausible values only (5–20 g/dL)\n",
    "m.loc[~m[\"hb_gdl\"].between(5, 20), \"hb_gdl\"] = pd.NA\n",
    "\n",
    "print(\"Hb non-missing after scaling & cleaning:\", m[\"hb_gdl\"].notna().sum())\n",
    "\n",
    "m.to_parquet(\"nfhs5_women_biomarkers.parquet\", index=False)\n",
    "print(\"Saved with corrected Hb → nfhs5_women_biomarkers.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c0d917-8216-4ee7-87dd-b8d1f8c88f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all five measures present: 682775\n",
      "Saved → nfhs5_women_flags.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "\n",
    "# ---- thresholds (easy to change later) ----\n",
    "cfg = {\n",
    "    \"bmi_abn_ge\": 23.0,    # abnormal if BMI >= 23 (Asian risk cut according to WHO )\n",
    "    \"bp_sbp_ge\": 140,      # abnormal if SBP >= 140\n",
    "    \"bp_dbp_ge\": 90,       # OR DBP >= 90\n",
    "    \"glucose_abn_ge\": 200, # random glucose >= 200 mg/dL\n",
    "    \"waist_f_ge_cm\": 80,   # female waist >= 80 cm (South Asian according to WHO )\n",
    "    \"hb_f_lt_gdl\": 12.0    # hemoglobin < 12.0 g/dL\n",
    "}\n",
    "\n",
    "# ---- flags (True = abnormal; NA if metric missing) ----\n",
    "m[\"BMI_abn\"]   = (m[\"bmi\"]             >= cfg[\"bmi_abn_ge\"])\n",
    "m[\"BP_abn\"]    = (m[\"sbp_clean\"]       >= cfg[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= cfg[\"bp_dbp_ge\"])\n",
    "m[\"GLU_abn\"]   = (m[\"glucose_mgdl\"]    >= cfg[\"glucose_abn_ge\"])\n",
    "m[\"WAIST_abn\"] = (m[\"waist_cm\"]        >= cfg[\"waist_f_ge_cm\"])\n",
    "m[\"HGB_abn\"]   = (m[\"hb_gdl\"]          <  cfg[\"hb_f_lt_gdl\"])\n",
    "\n",
    "\n",
    "for c in [\"BMI_abn\",\"BP_abn\",\"GLU_abn\",\"WAIST_abn\",\"HGB_abn\"]:\n",
    "    m[c] = m[c].astype(\"boolean\")\n",
    "\n",
    "\n",
    "m[\"num_abnormal\"] = m[[\"BMI_abn\",\"BP_abn\",\"GLU_abn\",\"WAIST_abn\",\"HGB_abn\"]].sum(axis=1, min_count=1)\n",
    "\n",
    "# \"Fully normal (strict) = all five metrics present AND all five normal\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "none_abnormal = ~m[[\"BMI_abn\",\"BP_abn\",\"GLU_abn\",\"WAIST_abn\",\"HGB_abn\"]].any(axis=1)\n",
    "m[\"fully_normal_strict\"] = (present_all5 & none_abnormal).astype(\"boolean\")\n",
    "\n",
    "print(\"Rows with all five measures present:\", int(present_all5.sum()))\n",
    "print(\"Saved → nfhs5_women_flags.parquet\")\n",
    "\n",
    "# Save a new file with flags\n",
    "m.to_parquet(\"nfhs5_women_flags.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbdabbde-b3a4-4b92-bfe9-ec1a835258ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total women (IR): 724115\n",
      "All five measures present: 682775\n",
      "\n",
      "Per-metric abnormality (unweighted):\n",
      "             Metric  Denominator (non-missing)  Abnormal (count)  Abnormal (%)\n",
      "       BMI abnormal                     724115            256165         35.38\n",
      "        BP abnormal                     724115             71505          9.87\n",
      "   Glucose abnormal                     724115              7924          1.09\n",
      "     Waist abnormal                     724115            271354         37.47\n",
      "Hemoglobin abnormal                     724115            393111         54.29\n",
      "\n",
      "Fully normal (strict):\n",
      "  Count: 129928\n",
      "  % among those with all five present: 19.03\n",
      "  % among all women: 17.94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "N = len(m)\n",
    "\n",
    "# Recompute\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "n_all5 = int(present_all5.sum())\n",
    "\n",
    "def summarize(flag_col):\n",
    "    denom = int(m[flag_col].notna().sum())             # women with this metric present\n",
    "    abn   = int(m[flag_col].sum(skipna=True))          # count abnormal\n",
    "    pct   = (abn / denom * 100) if denom else 0.0\n",
    "    return denom, abn, pct\n",
    "\n",
    "rows = []\n",
    "for name, col in [\n",
    "    (\"BMI abnormal\",   \"BMI_abn\"),\n",
    "    (\"BP abnormal\",    \"BP_abn\"),\n",
    "    (\"Glucose abnormal\",\"GLU_abn\"),\n",
    "    (\"Waist abnormal\", \"WAIST_abn\"),\n",
    "    (\"Hemoglobin abnormal\",\"HGB_abn\"),\n",
    "]:\n",
    "    d, a, p = summarize(col)\n",
    "    rows.append([name, d, a, round(p, 2)])\n",
    "\n",
    "summary = pd.DataFrame(rows, columns=[\"Metric\", \"Denominator (non-missing)\", \"Abnormal (count)\", \"Abnormal (%)\"])\n",
    "\n",
    "fully_normal_count = int(m[\"fully_normal_strict\"].sum())\n",
    "fully_normal_pct_of_all5 = round(fully_normal_count / n_all5 * 100, 2) if n_all5 else 0.0\n",
    "fully_normal_pct_of_all  = round(fully_normal_count / N * 100, 2)\n",
    "\n",
    "print(\"Total women (IR):\", N)\n",
    "print(\"All five measures present:\", n_all5)\n",
    "print(\"\\nPer-metric abnormality (unweighted):\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nFully normal (strict):\")\n",
    "print(\"  Count:\", fully_normal_count)\n",
    "print(\"  % among those with all five present:\", fully_normal_pct_of_all5)\n",
    "print(\"  % among all women:\", fully_normal_pct_of_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83ee940-59e8-4e09-b1f2-c0365317e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total women: 724115\n",
      "All five measures present: 682775\n",
      "\n",
      "Per-metric abnormality (correct denominators):\n",
      "             Metric  Denominator (has data)  Abnormal (count)  Abnormal (%)\n",
      "       BMI abnormal                  699362            256165         36.63\n",
      "        BP abnormal                  698956             71505         10.23\n",
      "   Glucose abnormal                  690636              7924          1.15\n",
      "     Waist abnormal                  697562            271354         38.90\n",
      "Hemoglobin abnormal                  688803            393111         57.07\n",
      "\n",
      "Fully normal (strict):\n",
      "  Count: 129928\n",
      "  % among those with all five present: 19.03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "N = len(m)\n",
    "\n",
    "\n",
    "den_bmi   = m[\"bmi\"].notna()\n",
    "den_bp    = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()  \n",
    "den_glu   = m[\"glucose_mgdl\"].notna()\n",
    "den_waist = m[\"waist_cm\"].notna()\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "\n",
    "def pct(abn_mask, denom_mask):\n",
    "    d = int(denom_mask.sum())\n",
    "    a = int((abn_mask & denom_mask).sum())\n",
    "    p = round(a / d * 100, 2) if d else 0.0\n",
    "    return d, a, p\n",
    "\n",
    "rows = []\n",
    "rows.append([\"BMI abnormal\",       *pct(m[\"BMI_abn\"].fillna(False),   den_bmi)])\n",
    "rows.append([\"BP abnormal\",        *pct(m[\"BP_abn\"].fillna(False),    den_bp)])\n",
    "rows.append([\"Glucose abnormal\",   *pct(m[\"GLU_abn\"].fillna(False),   den_glu)])\n",
    "rows.append([\"Waist abnormal\",     *pct(m[\"WAIST_abn\"].fillna(False), den_waist)])\n",
    "rows.append([\"Hemoglobin abnormal\",*pct(m[\"HGB_abn\"].fillna(False),   den_hb)])\n",
    "\n",
    "summary = pd.DataFrame(rows, columns=[\"Metric\",\"Denominator (has data)\",\"Abnormal (count)\",\"Abnormal (%)\"])\n",
    "\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "fully_normal_count = int((m[\"fully_normal_strict\"] == True).sum())\n",
    "pct_all5 = round(fully_normal_count / int(present_all5.sum()) * 100, 2)\n",
    "\n",
    "print(\"Total women:\", N)\n",
    "print(\"All five measures present:\", int(present_all5.sum()))\n",
    "print(\"\\nPer-metric abnormality (correct denominators):\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nFully normal (strict):\")\n",
    "print(\"  Count:\", fully_normal_count)\n",
    "print(\"  % among those with all five present:\", pct_all5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdbe7bcc-8f93-4de3-a2ba-2103b66b936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-metric abnormality (WEIGHTED):\n",
      "             Metric  Weighted denom  Weighted abn  Abnormal % (weighted)\n",
      "       BMI abnormal   692238.047527 262689.243412                  37.95\n",
      "        BP abnormal   691659.557342  68332.336879                   9.88\n",
      "   Glucose abnormal   682514.040153   9690.759483                   1.42\n",
      "     Waist abnormal   690490.016182 283364.520297                  41.04\n",
      "Hemoglobin abnormal   680847.669495 394172.621241                  57.89\n",
      "\n",
      "Fully normal (strict) — WEIGHTED:\n",
      "  % among those with all five present: 18.25\n",
      "  % among all women: 17.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "\n",
    "\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "\n",
    "den_bmi   = m[\"bmi\"].notna()\n",
    "den_bp    = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()\n",
    "den_glu   = m[\"glucose_mgdl\"].notna()\n",
    "den_waist = m[\"waist_cm\"].notna()\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "\n",
    "def wshare(flag_col, denom_mask):\n",
    "    \n",
    "    abn = m[flag_col].fillna(False).astype(int)\n",
    "    num = (abn * w).where(denom_mask, 0).sum()\n",
    "    den = w.where(denom_mask, 0).sum()\n",
    "    pct = float(num / den * 100) if den > 0 else 0.0\n",
    "    return den, num, round(pct, 2)\n",
    "\n",
    "rows = []\n",
    "rows.append([\"BMI abnormal\",        *wshare(\"BMI_abn\",   den_bmi)])\n",
    "rows.append([\"BP abnormal\",         *wshare(\"BP_abn\",    den_bp)])\n",
    "rows.append([\"Glucose abnormal\",    *wshare(\"GLU_abn\",   den_glu)])\n",
    "rows.append([\"Waist abnormal\",      *wshare(\"WAIST_abn\", den_waist)])\n",
    "rows.append([\"Hemoglobin abnormal\", *wshare(\"HGB_abn\",   den_hb)])\n",
    "\n",
    "summary_w = pd.DataFrame(rows, columns=[\"Metric\",\"Weighted denom\",\"Weighted abn\",\"Abnormal % (weighted)\"])\n",
    "\n",
    "# Fully normal (strict): weighted among those with all five present\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "fully_norm = (m[\"fully_normal_strict\"] == True).astype(int)\n",
    "\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "num_all5_w = (fully_norm * w).where(present_all5, 0).sum()\n",
    "pct_all5_w = round(float(num_all5_w / den_all5_w * 100), 2) if den_all5_w > 0 else 0.0\n",
    "\n",
    " #weighted among all women (even if some metrics missing)\n",
    "den_all_w = w.sum()\n",
    "num_all_w = (fully_norm * w).sum()\n",
    "pct_all_w = round(float(num_all_w / den_all_w * 100), 2)\n",
    "\n",
    "print(\"Per-metric abnormality (WEIGHTED):\")\n",
    "print(summary_w.to_string(index=False))\n",
    "\n",
    "print(\"\\nFully normal (strict) — WEIGHTED:\")\n",
    "print(\"  % among those with all five present:\", pct_all5_w)\n",
    "print(\"  % among all women:\", pct_all_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5722c7bb-d300-4359-8c6d-2579b072fbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hb abnormal (weighted):\n",
      "  Base Hb<12.0  : 57.89%\n",
      "  Liberal Hb<11.5: 45.35%\n",
      "\n",
      "Fully normal across all 5 (weighted, among all five present):\n",
      "  Base Hb<12.0  : 18.25%\n",
      "  Liberal Hb<11.5: 24.25%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "\n",
    "# --- BASE (Hb < 12.0) ---\n",
    "HGB_abn_base = m[\"HGB_abn\"].fillna(False).astype(int)\n",
    "den_hb_w  = w.where(den_hb, 0).sum()\n",
    "num_hb_w  = (HGB_abn_base * w).where(den_hb, 0).sum()\n",
    "pct_hb_w  = float(num_hb_w / den_hb_w * 100)\n",
    "\n",
    "fully_norm_base = (m[\"fully_normal_strict\"] == True).astype(int)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "num_all5_w = (fully_norm_base * w).where(present_all5, 0).sum()\n",
    "pct_all5_w_base = float(num_all5_w / den_all5_w * 100)\n",
    "\n",
    "# --- LIBERAL Hb (Hb < 11.5) ---\n",
    "HGB_abn_115 = (m[\"hb_gdl\"] < 11.5).fillna(False).astype(int)\n",
    "\n",
    "# recompute \"fully normal\" under the new Hb rule (other 4 flags unchanged)\n",
    "none_abn_others = (~m[\"BMI_abn\"]) & (~m[\"BP_abn\"]) & (~m[\"GLU_abn\"]) & (~m[\"WAIST_abn\"])\n",
    "fully_norm_115 = (present_all5 & none_abn_others & ~(m[\"hb_gdl\"] < 11.5)).astype(int)\n",
    "\n",
    "num_hb_w_115 = (HGB_abn_115 * w).where(den_hb, 0).sum()\n",
    "pct_hb_w_115 = float(num_hb_w_115 / den_hb_w * 100)\n",
    "\n",
    "num_all5_w_115 = (fully_norm_115 * w).where(present_all5, 0).sum()\n",
    "pct_all5_w_115 = float(num_all5_w_115 / den_all5_w * 100)\n",
    "\n",
    "print(\"Hb abnormal (weighted):\")\n",
    "print(f\"  Base Hb<12.0  : {pct_hb_w:5.2f}%\")\n",
    "print(f\"  Liberal Hb<11.5: {pct_hb_w_115:5.2f}%\")\n",
    "\n",
    "print(\"\\nFully normal across all 5 (weighted, among all five present):\")\n",
    "print(f\"  Base Hb<12.0  : {pct_all5_w_base:5.2f}%\")\n",
    "print(f\"  Liberal Hb<11.5: {pct_all5_w_115:5.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef2a5d9-b4be-41cb-8354-c2956f019e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP abnormal (weighted):\n",
      "  Base BP≥140/90 :  9.88%\n",
      "  Tight BP≥130/80: 39.11%\n",
      "\n",
      "Fully normal across all 5 (weighted, among all five present):\n",
      "  Base (with 140/90): 18.25%\n",
      "  With 130/80      : 13.11%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "# Denominators\n",
    "den_bp = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "\n",
    "# --- BASE BP (140/90) ---\n",
    "bp_abn_base = m[\"BP_abn\"].fillna(False).astype(int)\n",
    "den_bp_w = w.where(den_bp, 0).sum()\n",
    "num_bp_w = (bp_abn_base * w).where(den_bp, 0).sum()\n",
    "pct_bp_base = float(num_bp_w / den_bp_w * 100)\n",
    "\n",
    "# --- TIGHT BP (130/80) ---\n",
    "bp_abn_13080 = ((m[\"sbp_clean\"] >= 130) | (m[\"dbp_clean\"] >= 80)).fillna(False).astype(int)\n",
    "num_bp_w_13080 = (bp_abn_13080 * w).where(den_bp, 0).sum()\n",
    "pct_bp_13080 = float(num_bp_w_13080 / den_bp_w * 100)\n",
    "\n",
    "# Fully normal among those with all five present\n",
    "# For base: the saved flag (already 140/90, Hb<12)\n",
    "fully_norm_base = (m[\"fully_normal_strict\"] == True).astype(int)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "num_all5_w_base = (fully_norm_base * w).where(present_all5, 0).sum()\n",
    "pct_all5_base = float(num_all5_w_base / den_all5_w * 100)\n",
    "\n",
    "# For 130/80: recompute only the BP part; other 4 flags unchanged\n",
    "none_abn_others = (~m[\"BMI_abn\"]) & (~m[\"GLU_abn\"]) & (~m[\"WAIST_abn\"]) & (~m[\"HGB_abn\"])\n",
    "fully_norm_bp13080 = (present_all5 & none_abn_others & ~( (m[\"sbp_clean\"] >= 130) | (m[\"dbp_clean\"] >= 80) )).astype(int)\n",
    "num_all5_w_bp13080 = (fully_norm_bp13080 * w).where(present_all5, 0).sum()\n",
    "pct_all5_bp13080 = float(num_all5_w_bp13080 / den_all5_w * 100)\n",
    "\n",
    "print(\"BP abnormal (weighted):\")\n",
    "print(f\"  Base BP≥140/90 : {pct_bp_base:5.2f}%\")\n",
    "print(f\"  Tight BP≥130/80: {pct_bp_13080:5.2f}%\")\n",
    "\n",
    "print(\"\\nFully normal across all 5 (weighted, among all five present):\")\n",
    "print(f\"  Base (with 140/90): {pct_all5_base:5.2f}%\")\n",
    "print(f\"  With 130/80      : {pct_all5_bp13080:5.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f07c014c-e8b6-48ae-b331-a7c176a92f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Scenario  BP abnormal % (w)  Hb abnormal % (w)  Fully normal % (w, all 5 present)\n",
      "BP≥140/90, Hb<12.0               9.88              57.89                              18.25\n",
      "BP≥140/90, Hb<11.5               9.88              45.35                              24.25\n",
      "BP≥130/80, Hb<12.0              39.11              57.89                              13.11\n",
      "BP≥130/80, Hb<11.5              39.11              45.35                              17.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_flags.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "\n",
    "#  BMI/Waist/Glucose as in base flags only vary Hb and BP cutoffs here\n",
    "base_other_ok = (~m[\"BMI_abn\"]) & (~m[\"GLU_abn\"]) & (~m[\"WAIST_abn\"])\n",
    "\n",
    "def calc(bp_sbp_ge, bp_dbp_ge, hb_lt):\n",
    "    # BP abnormal under this cutoff\n",
    "    bp_abn = ((m[\"sbp_clean\"] >= bp_sbp_ge) | (m[\"dbp_clean\"] >= bp_dbp_ge)).fillna(False).astype(int)\n",
    "    den_bp = (m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna())\n",
    "    num_bp_w = (bp_abn * w).where(den_bp, 0).sum()\n",
    "    den_bp_w = w.where(den_bp, 0).sum()\n",
    "    pct_bp = float(num_bp_w / den_bp_w * 100) if den_bp_w > 0 else 0.0\n",
    "\n",
    "    # Hb abnormal under this cutoff\n",
    "    hb_abn = (m[\"hb_gdl\"] < hb_lt).fillna(False).astype(int)\n",
    "    den_hb = m[\"hb_gdl\"].notna()\n",
    "    num_hb_w = (hb_abn * w).where(den_hb, 0).sum()\n",
    "    den_hb_w = w.where(den_hb, 0).sum()\n",
    "    pct_hb = float(num_hb_w / den_hb_w * 100) if den_hb_w > 0 else 0.0\n",
    "\n",
    "    # Fully normal across all 5 with these Hb/BP rules (other three fixed at base)\n",
    "    fully_norm = (present_all5 & base_other_ok & ~(bp_abn.astype(bool)) & ~(m[\"hb_gdl\"] < hb_lt)).astype(int)\n",
    "    num_all5_w = (fully_norm * w).where(present_all5, 0).sum()\n",
    "    pct_all5 = float(num_all5_w / den_all5_w * 100) if den_all5_w > 0 else 0.0\n",
    "\n",
    "    return round(pct_bp,2), round(pct_hb,2), round(pct_all5,2)\n",
    "\n",
    "rows = []\n",
    "scenarios = [\n",
    "    (\"BP≥140/90, Hb<12.0\", 140, 90, 12.0),\n",
    "    (\"BP≥140/90, Hb<11.5\", 140, 90, 11.5),\n",
    "    (\"BP≥130/80, Hb<12.0\", 130, 80, 12.0),\n",
    "    (\"BP≥130/80, Hb<11.5\", 130, 80, 11.5),\n",
    "]\n",
    "for label, sbp, dbp, hb in scenarios:\n",
    "    bp, hb_, all5 = calc(sbp, dbp, hb)\n",
    "    rows.append([label, bp, hb_, all5])\n",
    "\n",
    "out = pd.DataFrame(rows, columns=[\"Scenario\",\"BP abnormal % (w)\",\"Hb abnormal % (w)\",\"Fully normal % (w, all 5 present)\"])\n",
    "print(out.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76e6564b-4109-480e-ac5a-882731b8fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote thresholds.yml\n"
     ]
    }
   ],
   "source": [
    "yaml_text = \"\"\"threshold_sets:\n",
    "  - name: base\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: liberal_hgb\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 11.5\n",
    "\n",
    "  - name: tight_bp\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: tight_bp__liberal_hgb\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 11.5\n",
    "\"\"\"\n",
    "with open(\"thresholds.yml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(yaml_text)\n",
    "print(\"Wrote thresholds.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "394ec5ac-bee6-443b-920e-f886881fb23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: base\n",
      "             Metric  Abnormal % (weighted)\n",
      "       BMI abnormal                  37.95\n",
      "        BP abnormal                   9.88\n",
      "   Glucose abnormal                   1.42\n",
      "     Waist abnormal                  41.04\n",
      "Hemoglobin abnormal                  57.89\n",
      "\n",
      "Fully normal % (weighted, among all 5 present): 18.25%\n"
     ]
    }
   ],
   "source": [
    "# thresholds.yml and compute weighted stats for a chosen scenario\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "#  read YAML\n",
    "try:\n",
    "    import yaml\n",
    "except Exception:\n",
    "    \n",
    "    %pip install pyyaml\n",
    "    import yaml\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "\n",
    "den_bmi   = m[\"bmi\"].notna()\n",
    "den_bp    = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()\n",
    "den_glu   = m[\"glucose_mgdl\"].notna()\n",
    "den_waist = m[\"waist_cm\"].notna()\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "\n",
    "def wshare_bool(flag_bool, denom_mask):\n",
    "    \"\"\"Weighted % with proper denominator (who has that metric).\"\"\"\n",
    "    num = (flag_bool.astype(int) * w).where(denom_mask, 0).sum()\n",
    "    den = w.where(denom_mask, 0).sum()\n",
    "    return (float(num/den*100) if den>0 else 0.0)\n",
    "\n",
    "def run_scenario(scn_name=\"base\"):\n",
    "    \n",
    "    with open(\"thresholds.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg_all = yaml.safe_load(f)\n",
    "    names = [s[\"name\"] for s in cfg_all[\"threshold_sets\"]]\n",
    "    if scn_name not in names:\n",
    "        print(\"Available scenarios:\", names)\n",
    "        raise SystemExit(f\"Scenario '{scn_name}' not found.\")\n",
    "    cfg = {k:v for s in cfg_all[\"threshold_sets\"] if s[\"name\"]==scn_name for k,v in s.items() if k!=\"name\"}\n",
    "\n",
    "    \n",
    "    BMI_abn   = (m[\"bmi\"]          >= cfg[\"bmi_abn_ge\"]).fillna(False)\n",
    "    BP_abn    = ((m[\"sbp_clean\"]   >= cfg[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= cfg[\"bp_dbp_ge\"])).fillna(False)\n",
    "    GLU_abn   = (m[\"glucose_mgdl\"] >= cfg[\"glucose_abn_ge\"]).fillna(False)\n",
    "    WAIST_abn = (m[\"waist_cm\"]     >= cfg[\"waist_f_ge_cm\"]).fillna(False)\n",
    "    HGB_abn   = (m[\"hb_gdl\"]       <  cfg[\"hb_f_lt_gdl\"]).fillna(False)\n",
    "\n",
    "    # 4) Weighted per-metric abnormality\n",
    "    out_rows = []\n",
    "    out_rows.append((\"BMI abnormal\",        round(wshare_bool(BMI_abn,   den_bmi),   2)))\n",
    "    out_rows.append((\"BP abnormal\",         round(wshare_bool(BP_abn,    den_bp),    2)))\n",
    "    out_rows.append((\"Glucose abnormal\",    round(wshare_bool(GLU_abn,   den_glu),   2)))\n",
    "    out_rows.append((\"Waist abnormal\",      round(wshare_bool(WAIST_abn, den_waist), 2)))\n",
    "    out_rows.append((\"Hemoglobin abnormal\", round(wshare_bool(HGB_abn,   den_hb),    2)))\n",
    "    summary = pd.DataFrame(out_rows, columns=[\"Metric\",\"Abnormal % (weighted)\"])\n",
    "\n",
    "    # 5) Weighted \"fully normal\" among those with all five present\n",
    "    none_abn = ~(BMI_abn | BP_abn | GLU_abn | WAIST_abn | HGB_abn)\n",
    "    fully_norm = (present_all5 & none_abn)\n",
    "    num_all5_w = (fully_norm.astype(int) * w).where(present_all5, 0).sum()\n",
    "    pct_all5   = round(float(num_all5_w / den_all5_w * 100), 2) if den_all5_w>0 else 0.0\n",
    "\n",
    "    print(f\"\\nScenario: {scn_name}\")\n",
    "    print(summary.to_string(index=False))\n",
    "    print(f\"\\nFully normal % (weighted, among all 5 present): {pct_all5:.2f}%\")\n",
    "    return summary, pct_all5\n",
    "\n",
    "\n",
    "_ = run_scenario(\"base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cca19a94-29ca-4ccf-af3a-1126124fec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: liberal_hgb\n",
      "             Metric  Abnormal % (weighted)\n",
      "       BMI abnormal                  37.95\n",
      "        BP abnormal                   9.88\n",
      "   Glucose abnormal                   1.42\n",
      "     Waist abnormal                  41.04\n",
      "Hemoglobin abnormal                  45.35\n",
      "\n",
      "Fully normal % (weighted, among all 5 present): 24.25%\n",
      "\n",
      "Scenario: tight_bp\n",
      "             Metric  Abnormal % (weighted)\n",
      "       BMI abnormal                  37.95\n",
      "        BP abnormal                  39.11\n",
      "   Glucose abnormal                   1.42\n",
      "     Waist abnormal                  41.04\n",
      "Hemoglobin abnormal                  57.89\n",
      "\n",
      "Fully normal % (weighted, among all 5 present): 13.11%\n",
      "\n",
      "Scenario: tight_bp__liberal_hgb\n",
      "             Metric  Abnormal % (weighted)\n",
      "       BMI abnormal                  37.95\n",
      "        BP abnormal                  39.11\n",
      "   Glucose abnormal                   1.42\n",
      "     Waist abnormal                  41.04\n",
      "Hemoglobin abnormal                  45.35\n",
      "\n",
      "Fully normal % (weighted, among all 5 present): 17.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                Metric  Abnormal % (weighted)\n",
       " 0         BMI abnormal                  37.95\n",
       " 1          BP abnormal                  39.11\n",
       " 2     Glucose abnormal                   1.42\n",
       " 3       Waist abnormal                  41.04\n",
       " 4  Hemoglobin abnormal                  45.35,\n",
       " 17.64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_scenario(\"liberal_hgb\")\n",
    "run_scenario(\"tight_bp\")\n",
    "run_scenario(\"tight_bp__liberal_hgb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "069f6e65-1732-4b85-91cf-ef69be337091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: section1_threshold_sensitivity.csv\n",
      "                scenario  BMI_abn_w%  BP_abn_w%  GLU_abn_w%  WAIST_abn_w%  \\\n",
      "0                   base       37.95       9.88        1.42         41.04   \n",
      "1            liberal_hgb       37.95       9.88        1.42         41.04   \n",
      "2               tight_bp       37.95      39.11        1.42         41.04   \n",
      "3  tight_bp__liberal_hgb       37.95      39.11        1.42         41.04   \n",
      "\n",
      "   HGB_abn_w%  Fully_normal_w%_all5  \n",
      "0       57.89                 18.25  \n",
      "1       45.35                 24.25  \n",
      "2       57.89                 13.11  \n",
      "3       45.35                 17.64  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "\n",
    "den_bmi   = m[\"bmi\"].notna()\n",
    "den_bp    = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()\n",
    "den_glu   = m[\"glucose_mgdl\"].notna()\n",
    "den_waist = m[\"waist_cm\"].notna()\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "\n",
    "def wshare_bool(flag_bool, denom_mask):\n",
    "    num = (flag_bool.astype(int) * w).where(denom_mask, 0).sum()\n",
    "    den = w.where(denom_mask, 0).sum()\n",
    "    return float(num/den*100) if den>0 else 0.0\n",
    "\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    cfg_all = yaml.safe_load(f)[\"threshold_sets\"]\n",
    "\n",
    "rows = []\n",
    "for scn in cfg_all:\n",
    "    name = scn[\"name\"]\n",
    "    \n",
    "    BMI_abn   = (m[\"bmi\"]          >= scn[\"bmi_abn_ge\"]).fillna(False)\n",
    "    BP_abn    = ((m[\"sbp_clean\"]   >= scn[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= scn[\"bp_dbp_ge\"])).fillna(False)\n",
    "    GLU_abn   = (m[\"glucose_mgdl\"] >= scn[\"glucose_abn_ge\"]).fillna(False)\n",
    "    WAIST_abn = (m[\"waist_cm\"]     >= scn[\"waist_f_ge_cm\"]).fillna(False)\n",
    "    HGB_abn   = (m[\"hb_gdl\"]       <  scn[\"hb_f_lt_gdl\"]).fillna(False)\n",
    "\n",
    "    # Weighted % per metric\n",
    "    out = {\n",
    "        \"scenario\": name,\n",
    "        \"BMI_abn_w%\":        round(wshare_bool(BMI_abn,   den_bmi),   2),\n",
    "        \"BP_abn_w%\":         round(wshare_bool(BP_abn,    den_bp),    2),\n",
    "        \"GLU_abn_w%\":        round(wshare_bool(GLU_abn,   den_glu),   2),\n",
    "        \"WAIST_abn_w%\":      round(wshare_bool(WAIST_abn, den_waist), 2),\n",
    "        \"HGB_abn_w%\":        round(wshare_bool(HGB_abn,   den_hb),    2),\n",
    "    }\n",
    "\n",
    "    # Fully normal (weighted, among all five present)\n",
    "    none_abn = ~(BMI_abn | BP_abn | GLU_abn | WAIST_abn | HGB_abn)\n",
    "    fully_norm = (present_all5 & none_abn)\n",
    "    num_all5_w = (fully_norm.astype(int) * w).where(present_all5, 0).sum()\n",
    "    out[\"Fully_normal_w%_all5\"] = round(float(num_all5_w / den_all5_w * 100), 2) if den_all5_w>0 else 0.0\n",
    "\n",
    "    rows.append(out)\n",
    "\n",
    "sens = pd.DataFrame(rows)\n",
    "sens.to_csv(\"section1_threshold_sensitivity.csv\", index=False)\n",
    "print(\"Saved: section1_threshold_sensitivity.csv\")\n",
    "print(sens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72b498d7-2288-4b04-8396-931b4eaa6c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 co-abnormality combinations (weighted, base scenario; among women with all five measures):\n",
      "               combo  weighted_count  weighted_pct  #abnormal\n",
      "BMI+BP+GLU+WAIST+HGB     1107.276381          0.16          5\n",
      "    BMI+BP+WAIST+HGB    14283.990785          2.12          4\n",
      "   BMI+GLU+WAIST+HGB     2182.510784          0.32          4\n",
      "    BMI+BP+GLU+WAIST     1347.570634          0.20          4\n",
      "    BP+GLU+WAIST+HGB      170.360220          0.03          4\n",
      "      BMI+BP+GLU+HGB       90.104469          0.01          4\n",
      "       BMI+WAIST+HGB    86640.024993         12.84          3\n",
      "        BMI+BP+WAIST    15940.022946          2.36          3\n",
      "        BP+WAIST+HGB     3348.574009          0.50          3\n",
      "          BMI+BP+HGB     2856.860210          0.42          3\n",
      "       BMI+GLU+WAIST     2108.110935          0.31          3\n",
      "       GLU+WAIST+HGB      320.907125          0.05          3\n",
      "         BMI+GLU+HGB      176.535526          0.03          3\n",
      "          BP+GLU+HGB      148.639675          0.02          3\n",
      "        BP+GLU+WAIST      133.793060          0.02          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "# Use only women who have all five measures\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "m = m.loc[present_all5].copy()\n",
    "w = w.loc[present_all5]\n",
    "\n",
    "# Read thresholds and pick the base scenario\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    cfg_all = yaml.safe_load(f)[\"threshold_sets\"]\n",
    "cfg = next(s for s in cfg_all if s[\"name\"]==\"base\")\n",
    "\n",
    "# Build flags under the base scenario\n",
    "BMI = (m[\"bmi\"]          >= cfg[\"bmi_abn_ge\"])\n",
    "BP  = (m[\"sbp_clean\"]    >= cfg[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= cfg[\"bp_dbp_ge\"])\n",
    "GLU = (m[\"glucose_mgdl\"] >= cfg[\"glucose_abn_ge\"])\n",
    "WAI = (m[\"waist_cm\"]     >= cfg[\"waist_f_ge_cm\"])\n",
    "HGB = (m[\"hb_gdl\"]       <  cfg[\"hb_f_lt_gdl\"])\n",
    "\n",
    "flags = pd.DataFrame({\"BMI\":BMI, \"BP\":BP, \"GLU\":GLU, \"WAIST\":WAI, \"HGB\":HGB})\n",
    "\n",
    "# Encode each row combination as a label like \"BMI+WAIST+HGB\" (or \"NONE\" if all False)\n",
    "def combo_label(row):\n",
    "    names = [k for k,v in row.items() if v]\n",
    "    return \"+\".join(names) if names else \"NONE\"\n",
    "\n",
    "combos = flags.apply(combo_label, axis=1)\n",
    "\n",
    "# Weighted counts & shares among all-five-present\n",
    "den_w = w.sum()\n",
    "out = (pd.DataFrame({\"combo\":combos, \"w\":w})\n",
    "         .groupby(\"combo\", as_index=False)[\"w\"].sum()\n",
    "         .assign(pct=lambda d: d[\"w\"]/den_w*100,\n",
    "                 k_abn=lambda d: d[\"combo\"].str.count(r\"\\+\") + (d[\"combo\"]!=\"NONE\").astype(int))\n",
    "         .sort_values([\"k_abn\",\"pct\"], ascending=[False, False]))\n",
    "\n",
    "# Show the top 15 combinations\n",
    "top15 = out.head(15).copy()\n",
    "top15[\"pct\"] = top15[\"pct\"].round(2)\n",
    "top15.rename(columns={\"w\":\"weighted_count\",\"pct\":\"weighted_pct\",\"k_abn\":\"#abnormal\"}, inplace=True)\n",
    "\n",
    "print(\"Top 15 co-abnormality combinations (weighted, base scenario; among women with all five measures):\")\n",
    "print(top15.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44768255-42f5-4640-bf6c-0718d427e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More-than-chance co-abnormalities (weighted, base; among women with all five measures):\n",
      "            combo  #abnormal  obs_pct  exp_pct  enrichment\n",
      "     BMI+BP+WAIST          3     2.36     0.61        3.90\n",
      "    BMI+GLU+WAIST          3     0.31     0.08        3.74\n",
      "BMI+GLU+WAIST+HGB          4     0.32     0.11        2.82\n",
      " BMI+BP+WAIST+HGB          4     2.12     0.83        2.55\n",
      "        BMI+WAIST          2    10.66     5.82        1.83\n",
      "    BMI+WAIST+HGB          3    12.84     7.99        1.61\n",
      "              HGB          1    29.22    19.00        1.54\n",
      "             NONE          0    18.25    13.83        1.32\n",
      "               BP          1     1.12     1.44        0.78\n",
      "           BP+HGB          2     1.49     1.98        0.75\n",
      "           BMI+BP          2     0.44     0.87        0.51\n",
      "         BP+WAIST          2     0.49     1.00        0.49\n",
      "        WAIST+HGB          2     6.27    13.15        0.48\n",
      "            WAIST          1     4.53     9.57        0.47\n",
      "              BMI          1     3.54     8.40        0.42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml\n",
    "from math import prod\n",
    "\n",
    "# Load data + weights\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "# Keep only women with all 5 measures (so exact combos are well-defined)\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "m = m.loc[present_all5].copy()\n",
    "w = w.loc[present_all5]\n",
    "\n",
    "# Read thresholds  use the \"base\" scenario for now\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    cfg = next(s for s in yaml.safe_load(f)[\"threshold_sets\"] if s[\"name\"]==\"base\")\n",
    "\n",
    "# Build abnormal flags for base cut-offs\n",
    "flags = pd.DataFrame({\n",
    "    \"BMI\":  (m[\"bmi\"]          >= cfg[\"bmi_abn_ge\"]),\n",
    "    \"BP\":   (m[\"sbp_clean\"]    >= cfg[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= cfg[\"bp_dbp_ge\"]),\n",
    "    \"GLU\":  (m[\"glucose_mgdl\"] >= cfg[\"glucose_abn_ge\"]),\n",
    "    \"WAIST\":(m[\"waist_cm\"]     >= cfg[\"waist_f_ge_cm\"]),\n",
    "    \"HGB\":  (m[\"hb_gdl\"]       <  cfg[\"hb_f_lt_gdl\"]),\n",
    "})\n",
    "\n",
    "# Weighted marginal probabilities p(metric abnormal)\n",
    "den_w = w.sum()\n",
    "p = {}\n",
    "for col in flags.columns:\n",
    "    p[col] = ((flags[col].astype(int) * w).sum()) / den_w\n",
    "\n",
    "# Encode each row’s exact combo label (\"BMI+WAIST+HGB\" or \"NONE\")\n",
    "def combo_label(row):\n",
    "    ks = [k for k,v in row.items() if v]\n",
    "    return \"+\".join(ks) if ks else \"NONE\"\n",
    "\n",
    "combos = flags.apply(combo_label, axis=1)\n",
    "\n",
    "# Observed weighted % by combo\n",
    "obs = (pd.DataFrame({\"combo\": combos, \"w\": w})\n",
    "         .groupby(\"combo\", as_index=False)[\"w\"].sum())\n",
    "obs[\"obs_pct\"] = obs[\"w\"] / den_w * 100\n",
    "\n",
    "# Expected % under independence for the exact combo (product of p or (1-p))\n",
    "metrics = list(flags.columns)\n",
    "def expected_pct(combo_name):\n",
    "    if combo_name==\"NONE\":\n",
    "        # all five normal\n",
    "        terms = [(1-p[k]) for k in metrics]\n",
    "    else:\n",
    "        abn = set(combo_name.split(\"+\"))\n",
    "        terms = [ (p[k] if k in abn else (1-p[k])) for k in metrics ]\n",
    "    return prod(terms) * 100\n",
    "\n",
    "obs[\"exp_pct\"] = obs[\"combo\"].apply(expected_pct)\n",
    "\n",
    "# Enrichment ratio \n",
    "obs[\"enrichment\"] = obs[\"obs_pct\"] / obs[\"exp_pct\"].where(obs[\"exp_pct\"]>0, float(\"nan\"))\n",
    "obs[\"#abnormal\"]  = obs[\"combo\"].apply(lambda s: 0 if s==\"NONE\" else s.count(\"+\")+1)\n",
    "\n",
    "# Focus table: drop ultra-rare noise (expected < 0.05% or observed < 0.05%)\n",
    "focus = obs[(obs[\"exp_pct\"]>=0.05) & (obs[\"obs_pct\"]>=0.05)].copy()\n",
    "focus = focus.sort_values([\"enrichment\",\"obs_pct\"], ascending=[False, False])\n",
    "\n",
    "# Show top 15 by enrichment\n",
    "out = focus[[\"combo\",\"#abnormal\",\"obs_pct\",\"exp_pct\",\"enrichment\"]].head(15).copy()\n",
    "out[\"obs_pct\"] = out[\"obs_pct\"].round(2)\n",
    "out[\"exp_pct\"] = out[\"exp_pct\"].round(2)\n",
    "out[\"enrichment\"] = out[\"enrichment\"].round(2)\n",
    "\n",
    "print(\"More-than-chance co-abnormalities (weighted, base; among women with all five measures):\")\n",
    "print(out.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2bf304-734f-4c82-82ad-c1f2575cffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation test (state×urban shuffled), base scenario\n",
      "            combo   obs_pct  perm_mean_pct  perm_sd_pct  p_perm  q_fdr\n",
      "    BMI+WAIST+HGB 12.838606      12.838606 3.575128e-15     1.0    1.0\n",
      "        BMI+WAIST 10.663626      10.663626 1.787564e-15     1.0    1.0\n",
      "     BMI+BP+WAIST  2.362045       2.362045 4.468911e-16     1.0    1.0\n",
      " BMI+BP+WAIST+HGB  2.116649       2.116649 4.468911e-16     1.0    1.0\n",
      "BMI+GLU+WAIST+HGB  0.323412       0.323412 5.586138e-17     1.0    1.0\n",
      "    BMI+GLU+WAIST  0.312387       0.312387 0.000000e+00     1.0    1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml, numpy as np\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "\n",
    "m = m.loc[present_all5].copy()\n",
    "w = w.loc[present_all5]\n",
    "den_w = w.sum()\n",
    "\n",
    "\n",
    "strata = m[\"v024\"].astype(\"Int16\").astype(str) + \"_\" + m[\"v025\"].astype(\"Int8\").astype(str)\n",
    "strata = strata.to_numpy()\n",
    "\n",
    "# Base thresholds\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    base = next(s for s in yaml.safe_load(f)[\"threshold_sets\"] if s[\"name\"]==\"base\")\n",
    "\n",
    "BMI = (m[\"bmi\"]          >= base[\"bmi_abn_ge\"]).to_numpy()\n",
    "BP  = ((m[\"sbp_clean\"]   >= base[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= base[\"bp_dbp_ge\"])).to_numpy()\n",
    "GLU = (m[\"glucose_mgdl\"] >= base[\"glucose_abn_ge\"]).to_numpy()\n",
    "WAI = (m[\"waist_cm\"]     >= base[\"waist_f_ge_cm\"]).to_numpy()\n",
    "HGB = (m[\"hb_gdl\"]       <  base[\"hb_f_lt_gdl\"]).to_numpy()\n",
    "weights = w.to_numpy()\n",
    "\n",
    "# Observed combo % helper\n",
    "def pct_combo(mask):\n",
    "    return float(weights[mask].sum() / den_w * 100)\n",
    "\n",
    "# Observed table \n",
    "import itertools\n",
    "names = [\"BMI\",\"BP\",\"GLU\",\"WAIST\",\"HGB\"]\n",
    "flags = {\"BMI\":BMI, \"BP\":BP, \"GLU\":GLU, \"WAIST\":WAI, \"HGB\":HGB}\n",
    "\n",
    "def combo_mask(combo_names, f=flags):\n",
    "    msk = np.ones(len(weights), dtype=bool)\n",
    "    for k in names:  # exactly this combo: abns in combo, normals otherwise\n",
    "        if k in combo_names:\n",
    "            msk &= f[k]\n",
    "        else:\n",
    "            msk &= ~f[k]\n",
    "    return msk\n",
    "\n",
    "# Compute observed %s for all combos\n",
    "obs = []\n",
    "for r in range(0,6):\n",
    "    for comb in itertools.combinations(names, r):\n",
    "        label = \"+\".join(comb) if comb else \"NONE\"\n",
    "        msk = combo_mask(set(comb))\n",
    "        obs_pct = pct_combo(msk)\n",
    "        obs.append((label, r, obs_pct))\n",
    "obs_df = pd.DataFrame(obs, columns=[\"combo\",\"#abnormal\",\"obs_pct\"]).sort_values(\"obs_pct\", ascending=False)\n",
    "\n",
    "# Keep enriched combos (from your earlier independence table) and with obs_pct >= 0.2% and not NONE\n",
    "enriched_candidates = set([\"BMI+BP+WAIST\",\"BMI+GLU+WAIST\",\"BMI+GLU+WAIST+HGB\",\"BMI+BP+WAIST+HGB\",\"BMI+WAIST\",\"BMI+WAIST+HGB\"])\n",
    "test_combos = [c for c in obs_df[\"combo\"].tolist() if (c in enriched_candidates) and (c!=\"NONE\") and (obs_df.loc[obs_df[\"combo\"]==c,\"obs_pct\"].values[0] >= 0.2)]\n",
    "\n",
    "# --- Permutation within strata\n",
    "rng = np.random.default_rng(123)\n",
    "def shuffle_within_groups(arr, groups):\n",
    "    arr = arr.copy()\n",
    "    for g in np.unique(groups):\n",
    "        idx = np.where(groups==g)[0]\n",
    "        rng.shuffle(arr[idx])\n",
    "    return arr\n",
    "\n",
    "n_perm = 80  # adjust for speed vs precision\n",
    "\n",
    "perm_max = {c:[] for c in test_combos}\n",
    "for _ in range(n_perm):\n",
    "    BMI_p = shuffle_within_groups(BMI, strata)\n",
    "    BP_p  = shuffle_within_groups(BP, strata)\n",
    "    GLU_p = shuffle_within_groups(GLU, strata)\n",
    "    WAI_p = shuffle_within_groups(WAI, strata)\n",
    "    HGB_p = shuffle_within_groups(HGB, strata)\n",
    "    f = {\"BMI\":BMI_p, \"BP\":BP_p, \"GLU\":GLU_p, \"WAIST\":WAI_p, \"HGB\":HGB_p}\n",
    "    for c in test_combos:\n",
    "        comb = set(c.split(\"+\")) if c!=\"NONE\" else set()\n",
    "        msk = combo_mask(comb, f=f)\n",
    "        perm_max[c].append(pct_combo(msk))\n",
    "\n",
    "# One-sided p-values (Pr[perm ≥ obs]); add +1 smoothing\n",
    "results = []\n",
    "for c in test_combos:\n",
    "    obs_c = float(obs_df.loc[obs_df[\"combo\"]==c,\"obs_pct\"].values[0])\n",
    "    per = np.array(perm_max[c], dtype=float)\n",
    "    pval = ( (per >= obs_c).sum() + 1 ) / (len(per) + 1)\n",
    "    results.append((c, obs_c, float(per.mean()), float(per.std(ddof=1)), float(pval)))\n",
    "\n",
    "res = pd.DataFrame(results, columns=[\"combo\",\"obs_pct\",\"perm_mean_pct\",\"perm_sd_pct\",\"p_perm\"]).sort_values(\"p_perm\")\n",
    "# Benjamini–Hochberg FDR\n",
    "p = res[\"p_perm\"].to_numpy()\n",
    "order = np.argsort(p)\n",
    "rank = np.arange(1, len(p)+1)\n",
    "q = p[order] * len(p) / rank\n",
    "q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "q_adj = np.empty_like(q); q_adj[order] = np.clip(q, 0, 1)\n",
    "res[\"q_fdr\"] = q_adj\n",
    "\n",
    "print(\"Permutation test (state×urban shuffled), base scenario\")\n",
    "print(res.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c663c1fc-37c1-4f34-946b-8b2ea8c00fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: section1_combos_obs_vs_expected_base.csv\n",
      "               combo            w  obs_pct  exp_pct  enrichment  #abnormal\n",
      "BMI+BP+GLU+WAIST+HGB  1107.276381     0.16     0.01       13.74          5\n",
      "    BMI+BP+WAIST+HGB 14283.990785     2.12     0.83        2.55          4\n",
      "   BMI+GLU+WAIST+HGB  2182.510784     0.32     0.11        2.82          4\n",
      "    BMI+BP+GLU+WAIST  1347.570634     0.20     0.01       22.97          4\n",
      "    BP+GLU+WAIST+HGB   170.360220     0.03     0.02        1.28          4\n",
      "      BMI+BP+GLU+HGB    90.104469     0.01     0.02        0.77          4\n",
      "       BMI+WAIST+HGB 86640.024993    12.84     7.99        1.61          3\n",
      "        BMI+BP+WAIST 15940.022946     2.36     0.61        3.90          3\n",
      "        BP+WAIST+HGB  3348.574009     0.50     1.37        0.36          3\n",
      "          BMI+BP+HGB  2856.860210     0.42     1.20        0.35          3\n",
      "       BMI+GLU+WAIST  2108.110935     0.31     0.08        3.74          3\n",
      "       GLU+WAIST+HGB   320.907125     0.05     0.19        0.25          3\n",
      "         BMI+GLU+HGB   176.535526     0.03     0.17        0.16          3\n",
      "          BP+GLU+HGB   148.639675     0.02     0.03        0.78          3\n",
      "        BP+GLU+WAIST   133.793060     0.02     0.01        1.39          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml\n",
    "from math import prod\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "m = m.loc[present_all5].copy(); w = w.loc[present_all5]; den_w = w.sum()\n",
    "\n",
    "# Base thresholds\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    base = next(s for s in yaml.safe_load(f)[\"threshold_sets\"] if s[\"name\"]==\"base\")\n",
    "\n",
    "flags = pd.DataFrame({\n",
    "    \"BMI\":  (m[\"bmi\"]          >= base[\"bmi_abn_ge\"]),\n",
    "    \"BP\":   (m[\"sbp_clean\"]    >= base[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= base[\"bp_dbp_ge\"]),\n",
    "    \"GLU\":  (m[\"glucose_mgdl\"] >= base[\"glucose_abn_ge\"]),\n",
    "    \"WAIST\":(m[\"waist_cm\"]     >= base[\"waist_f_ge_cm\"]),\n",
    "    \"HGB\":  (m[\"hb_gdl\"]       <  base[\"hb_f_lt_gdl\"]),\n",
    "})\n",
    "\n",
    "# Weighted marginals\n",
    "p = {col: (flags[col].astype(int) * w).sum() / den_w for col in flags.columns}\n",
    "\n",
    "# Label exact combo per row\n",
    "def combo_label(row):\n",
    "    ks = [k for k,v in row.items() if v]\n",
    "    return \"+\".join(ks) if ks else \"NONE\"\n",
    "combos = flags.apply(combo_label, axis=1)\n",
    "\n",
    "# Observed weighted % by combo\n",
    "obs = (pd.DataFrame({\"combo\": combos, \"w\": w})\n",
    "         .groupby(\"combo\", as_index=False)[\"w\"].sum())\n",
    "obs[\"obs_pct\"] = obs[\"w\"] / den_w * 100\n",
    "\n",
    "\n",
    "metrics = list(flags.columns)\n",
    "def expected_pct(name):\n",
    "    if name==\"NONE\":\n",
    "        return prod([(1-p[k]) for k in metrics]) * 100\n",
    "    abn = set(name.split(\"+\"))\n",
    "    return prod([(p[k] if k in abn else (1-p[k])) for k in metrics]) * 100\n",
    "\n",
    "obs[\"exp_pct\"] = obs[\"combo\"].apply(expected_pct)\n",
    "obs[\"enrichment\"] = obs[\"obs_pct\"] / obs[\"exp_pct\"].where(obs[\"exp_pct\"]>0)\n",
    "obs[\"#abnormal\"]  = obs[\"combo\"].apply(lambda s: 0 if s==\"NONE\" else s.count(\"+\")+1)\n",
    "\n",
    "\n",
    "table = (obs.sort_values([\"#abnormal\",\"obs_pct\"], ascending=[False, False])\n",
    "           .assign(obs_pct=lambda d: d[\"obs_pct\"].round(2),\n",
    "                   exp_pct=lambda d: d[\"exp_pct\"].round(2),\n",
    "                   enrichment=lambda d: d[\"enrichment\"].round(2)))\n",
    "table.to_csv(\"section1_combos_obs_vs_expected_base.csv\", index=False)\n",
    "print(\"Saved: section1_combos_obs_vs_expected_base.csv\")\n",
    "print(table.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78359a19-91d7-4ad2-b7a0-686d1c386d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table → section1_upset_intersections_base.csv\n",
      "               combo              w  weighted_pct\n",
      "28               HGB  197196.246856     29.221193\n",
      "15     BMI+WAIST+HGB   86640.024993     12.838606\n",
      "14         BMI+WAIST   71962.397106     10.663626\n",
      "30         WAIST+HGB   42282.459273      6.265555\n",
      "29             WAIST   30598.991736      4.534260\n",
      "13           BMI+HGB   29170.547007      4.322588\n",
      "0                BMI   23887.419406      3.539717\n",
      "7       BMI+BP+WAIST   15940.022946      2.362045\n",
      "8   BMI+BP+WAIST+HGB   14283.990785      2.116649\n",
      "21            BP+HGB   10034.239143      1.486907\n",
      "Saved fallback figure → figs/top15_combos_base.png\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "m = m.loc[present_all5].copy()\n",
    "w = w.loc[present_all5]\n",
    "\n",
    "# 2) Base thresholds  abnormal flags\n",
    "with open(\"thresholds.yml\",\"r\",encoding=\"utf-8\") as f:\n",
    "    base = next(s for s in yaml.safe_load(f)[\"threshold_sets\"] if s[\"name\"]==\"base\")\n",
    "\n",
    "flags = pd.DataFrame({\n",
    "    \"BMI\":   (m[\"bmi\"]          >= base[\"bmi_abn_ge\"]),\n",
    "    \"BP\":    (m[\"sbp_clean\"]    >= base[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= base[\"bp_dbp_ge\"]),\n",
    "    \"GLU\":   (m[\"glucose_mgdl\"] >= base[\"glucose_abn_ge\"]),\n",
    "    \"WAIST\": (m[\"waist_cm\"]     >= base[\"waist_f_ge_cm\"]),\n",
    "    \"HGB\":   (m[\"hb_gdl\"]       <  base[\"hb_f_lt_gdl\"]),\n",
    "})\n",
    "\n",
    "# 3) Build human-readable combo labels per row \n",
    "combo_labels = flags.apply(lambda r: \"+\".join([c for c in [\"BMI\",\"BP\",\"GLU\",\"WAIST\",\"HGB\"] if r[c]]), axis=1)\n",
    "mask_any = flags.any(axis=1)\n",
    "combo_labels = combo_labels[mask_any]\n",
    "w_any = w[mask_any]\n",
    "\n",
    "# 4) Aggregate weighted counts per combo and save CSV\n",
    "intersections = (\n",
    "    pd.DataFrame({\"combo\": combo_labels, \"w\": w_any})\n",
    "      .groupby(\"combo\", as_index=False)[\"w\"].sum()\n",
    "      .assign(weighted_pct=lambda d: d[\"w\"] / w.sum() * 100)\n",
    "      .sort_values(\"w\", ascending=False)\n",
    ")\n",
    "\n",
    "intersections.to_csv(\"section1_upset_intersections_base.csv\", index=False)\n",
    "print(\"Saved table → section1_upset_intersections_base.csv\")\n",
    "print(intersections.head(10))\n",
    "\n",
    "# 5) Fallback figure: Top-15 combos bar chart (weighted %)\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "top15 = intersections.head(15).iloc[::-1]  # reverse for horizontal bars (small→large)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(top15[\"combo\"], top15[\"weighted_pct\"])\n",
    "plt.xlabel(\"Weighted % (among women with all 5 measures)\")\n",
    "plt.title(\"NFHS-5 (Women): Top-15 abnormality combinations — Base thresholds\")\n",
    "plt.tight_layout()\n",
    "out_path = \"figs/top15_combos_base.png\"\n",
    "plt.savefig(out_path, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved fallback figure →\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b18d382-8aac-4b5a-9a94-48fbfceeefce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: section1_threshold_sensitivity.csv\n",
      "                                scenario  BMI_abn_w%  BP_abn_w%  GLU_abn_w%  \\\n",
      "0                                   base       37.95       9.88        1.42   \n",
      "4                                  bmi25       23.88       9.88        1.42   \n",
      "6                         bmi25__waist88       23.88       9.88        1.42   \n",
      "7               bmi25__waist88__tight_bp       23.88      39.11        1.42   \n",
      "8  bmi25__waist88__tight_bp__liberal_hgb       23.88      39.11        1.42   \n",
      "1                            liberal_hgb       37.95       9.88        1.42   \n",
      "2                               tight_bp       37.95      39.11        1.42   \n",
      "3                  tight_bp__liberal_hgb       37.95      39.11        1.42   \n",
      "5                                waist88       37.95       9.88        1.42   \n",
      "\n",
      "   WAIST_abn_w%  HGB_abn_w%  Fully_normal_w%_all5  \n",
      "0         41.04       57.89                 18.25  \n",
      "4         41.04       57.89                 20.55  \n",
      "6         20.42       57.89                 26.07  \n",
      "7         20.42       57.89                 17.80  \n",
      "8         20.42       45.35                 23.81  \n",
      "1         41.04       45.35                 24.25  \n",
      "2         41.04       57.89                 13.11  \n",
      "3         41.04       45.35                 17.64  \n",
      "5         20.42       57.89                 21.68  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, yaml\n",
    "\n",
    "# --- write an extended thresholds.yml ---\n",
    "yaml_text = \"\"\"threshold_sets:\n",
    "  - name: base\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: liberal_hgb\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 11.5\n",
    "\n",
    "  - name: tight_bp\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: tight_bp__liberal_hgb\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 11.5\n",
    "\n",
    "  # --- NEW sensitivity presets ---\n",
    "  - name: bmi25\n",
    "    bmi_abn_ge: 25.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 80\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: waist88\n",
    "    bmi_abn_ge: 23.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 88\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: bmi25__waist88\n",
    "    bmi_abn_ge: 25.0\n",
    "    bp_sbp_ge: 140\n",
    "    bp_dbp_ge: 90\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 88\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: bmi25__waist88__tight_bp\n",
    "    bmi_abn_ge: 25.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 88\n",
    "    hb_f_lt_gdl: 12.0\n",
    "\n",
    "  - name: bmi25__waist88__tight_bp__liberal_hgb\n",
    "    bmi_abn_ge: 25.0\n",
    "    bp_sbp_ge: 130\n",
    "    bp_dbp_ge: 80\n",
    "    glucose_abn_ge: 200\n",
    "    waist_f_ge_cm: 88\n",
    "    hb_f_lt_gdl: 11.5\n",
    "\"\"\"\n",
    "with open(\"thresholds.yml\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "# I tried to recompute the weighted sensitivity table for ALL scenarios above \n",
    "m = pd.read_parquet(\"nfhs5_women_biomarkers.parquet\")\n",
    "w = pd.to_numeric(m[\"v005\"], errors=\"coerce\") / 1_000_000\n",
    "\n",
    "den_bmi   = m[\"bmi\"].notna()\n",
    "den_bp    = m[\"sbp_clean\"].notna() | m[\"dbp_clean\"].notna()\n",
    "den_glu   = m[\"glucose_mgdl\"].notna()\n",
    "den_waist = m[\"waist_cm\"].notna()\n",
    "den_hb    = m[\"hb_gdl\"].notna()\n",
    "present_all5 = m[[\"bmi\",\"sbp_clean\",\"dbp_clean\",\"glucose_mgdl\",\"waist_cm\",\"hb_gdl\"]].notna().all(axis=1)\n",
    "den_all5_w = w.where(present_all5, 0).sum()\n",
    "\n",
    "def wshare(flag_bool, denom_mask):\n",
    "    num = (flag_bool.astype(int) * w).where(denom_mask, 0).sum()\n",
    "    den = w.where(denom_mask, 0).sum()\n",
    "    return float(num/den*100) if den>0 else 0.0\n",
    "\n",
    "cfg_all = yaml.safe_load(open(\"thresholds.yml\",\"r\",encoding=\"utf-8\"))[\"threshold_sets\"]\n",
    "\n",
    "rows = []\n",
    "for scn in cfg_all:\n",
    "    name = scn[\"name\"]\n",
    "    BMI_abn   = (m[\"bmi\"]          >= scn[\"bmi_abn_ge\"]).fillna(False)\n",
    "    BP_abn    = ((m[\"sbp_clean\"]   >= scn[\"bp_sbp_ge\"]) | (m[\"dbp_clean\"] >= scn[\"bp_dbp_ge\"])).fillna(False)\n",
    "    GLU_abn   = (m[\"glucose_mgdl\"] >= scn[\"glucose_abn_ge\"]).fillna(False)\n",
    "    WAIST_abn = (m[\"waist_cm\"]     >= scn[\"waist_f_ge_cm\"]).fillna(False)\n",
    "    HGB_abn   = (m[\"hb_gdl\"]       <  scn[\"hb_f_lt_gdl\"]).fillna(False)\n",
    "\n",
    "    out = {\n",
    "        \"scenario\": name,\n",
    "        \"BMI_abn_w%\":        round(wshare(BMI_abn,   den_bmi),   2),\n",
    "        \"BP_abn_w%\":         round(wshare(BP_abn,    den_bp),    2),\n",
    "        \"GLU_abn_w%\":        round(wshare(GLU_abn,   den_glu),   2),\n",
    "        \"WAIST_abn_w%\":      round(wshare(WAIST_abn, den_waist), 2),\n",
    "        \"HGB_abn_w%\":        round(wshare(HGB_abn,   den_hb),    2),\n",
    "    }\n",
    "    none_abn = ~(BMI_abn | BP_abn | GLU_abn | WAIST_abn | HGB_abn)\n",
    "    fully_norm = (present_all5 & none_abn)\n",
    "    num_all5_w = (fully_norm.astype(int) * w).where(present_all5, 0).sum()\n",
    "    out[\"Fully_normal_w%_all5\"] = round(float(num_all5_w / den_all5_w * 100), 2) if den_all5_w>0 else 0.0\n",
    "    rows.append(out)\n",
    "\n",
    "sens = pd.DataFrame(rows).sort_values(\"scenario\")\n",
    "sens.to_csv(\"section1_threshold_sensitivity.csv\", index=False)\n",
    "print(\"Saved: section1_threshold_sensitivity.csv\")\n",
    "print(sens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1ecca-d1ec-49f7-b7de-937c9d6911cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
